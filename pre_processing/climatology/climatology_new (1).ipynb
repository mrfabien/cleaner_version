{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49cd137-6bdf-4716-9a49-1e1e84a5a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librairies\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the path to the custom library\n",
    "custom_library_path = os.path.abspath('/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/fabienVED')\n",
    "sys.path.append(custom_library_path)\n",
    "# set the directory path\n",
    "os.chdir('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/')\n",
    "\n",
    "\n",
    "import data_process\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a5859e-0a9d-4694-a016-d333efcbb498",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4465c1e9-3048-4345-921f-79d049c24850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "#upath = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5/SL/10m_u_component_of_wind/'\n",
    "#vpath = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5/SL/10m_v_component_of_wind/'\n",
    "ifg = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5/SL/instantaneous_10m_wind_gust/'\n",
    "\n",
    "# Date specification\n",
    "year = np.arange(1990,2021,1)\n",
    "#target_month = 2\n",
    "#target_day = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2277b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gather all the starting days of the 96 storms from the time series datasets\n",
    "\n",
    "# Load the time series datasets\n",
    "\n",
    "dates = pd.read_csv('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/data/time_series_1h_EU/instantaneous_10m_wind_gust/instantaneous_10m_wind_gust_max.csv')\n",
    "dates = dates['start_date']\n",
    "eu_final_raster = xr.open_dataset('pre_processing/maps/eu_final_raster.tif',\n",
    "                                    engine='rasterio')\n",
    "\n",
    "# rename x and y to lon and lat\n",
    "eu_final_raster = eu_final_raster.rename({'x':'longitude','y':'latitude'})\n",
    "\n",
    "# Extract the starting days of the 96 storms\n",
    "\n",
    "storm_dates = []\n",
    "for date in dates:\n",
    "    storm_dates.append(datetime.strptime(date, '%Y-%m-%dT%H:%M:%S'))\n",
    "\n",
    "# Extract each month and day of the storm starting days\n",
    "\n",
    "storm_year = []\n",
    "storm_month = []\n",
    "storm_day = []\n",
    "for date in storm_dates:\n",
    "    storm_year.append(date.year)\n",
    "    storm_month.append(date.month)\n",
    "    storm_day.append(date.day)\n",
    "\n",
    "# Combine the month and day of the storm starting days into a single list\n",
    "\n",
    "storm_year_month_day = []\n",
    "storm_month_day = []\n",
    "for i in range(len(storm_month)):\n",
    "    storm_year_month_day.append([storm_year[i],storm_month[i], storm_day[i]])\n",
    "    storm_month_day.append([storm_month[i], storm_day[i]])\n",
    "\n",
    "# keep the only the days that don't repeat themselves\n",
    "storm_month_day = np.array(storm_month_day)\n",
    "storm_month_day = np.unique(storm_month_day, axis=0)\n",
    "\n",
    "storm_year_month_day = np.array(storm_year_month_day)\n",
    "storm_year_month_day = np.unique(storm_year_month_day, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93f25bf-88e8-4452-bcd7-bfded9ecc742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 31/31 [00:45<00:00,  1.46s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:40<00:00,  1.30s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.37s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:48<00:00,  1.56s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.35s/it]\n",
      " 35%|█████████████████▍                               | 11/31 [00:16<00:29,  1.48s/it]\n",
      " 19%|█████████▏                                       | 11/59 [08:14<35:59, 44.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# parse date\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m first_true_index,last_true_index \u001b[38;5;241m=\u001b[39m \u001b[43mdata_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_date_and_output_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi10fg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_month\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_day\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Convert longitude from 0-360 to -180 to 180\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#u10['longitude'] = ((u10['longitude'] + 180) % 360) - 180\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#v10['longitude'] = ((v10['longitude'] + 180) % 360) - 180\u001b[39;00m\n\u001b[1;32m     47\u001b[0m i10fg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ((i10fg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m180\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m360\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m180\u001b[39m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/fabienVED/data_process.py:11\u001b[0m, in \u001b[0;36mparse_date_and_output_list\u001b[0;34m(u10, target_month, target_day)\u001b[0m\n\u001b[1;32m      9\u001b[0m date_ctrl \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(u10[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m---> 11\u001b[0m     tempdate \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;28mstr\u001b[39m(\u001b[43mu10\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdata), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS.\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m000\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((tempdate\u001b[38;5;241m.\u001b[39mmonth\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mint\u001b[39m(target_month)) \u001b[38;5;241m&\u001b[39m (tempdate\u001b[38;5;241m.\u001b[39mday\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mint\u001b[39m(target_day))):\n\u001b[1;32m     13\u001b[0m         date_ctrl\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/dataarray.py:899\u001b[0m, in \u001b[0;36mDataArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_coord(key)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# xarray-style array indexing\u001b[39;00m\n\u001b[0;32m--> 899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_item_key_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/dataarray.py:1547\u001b[0m, in \u001b[0;36mDataArray.isel\u001b[0;34m(self, indexers, drop, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m coord_indexers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1544\u001b[0m     k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m indexers\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m coord_value\u001b[38;5;241m.\u001b[39mdims\n\u001b[1;32m   1545\u001b[0m }\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coord_indexers:\n\u001b[0;32m-> 1547\u001b[0m     coord_value \u001b[38;5;241m=\u001b[39m \u001b[43mcoord_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoord_indexers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop \u001b[38;5;129;01mand\u001b[39;00m coord_value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1549\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:1038\u001b[0m, in \u001b[0;36mVariable.isel\u001b[0;34m(self, indexers, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m indexers \u001b[38;5;241m=\u001b[39m drop_dims_from_indexers(indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims, missing_dims)\n\u001b[1;32m   1037\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(indexers\u001b[38;5;241m.\u001b[39mget(dim, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims)\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:809\u001b[0m, in \u001b[0;36mVariable.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_order:\n\u001b[1;32m    808\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(data, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(new_order)), new_order)\n\u001b[0;32m--> 809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finalize_indexing_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:2687\u001b[0m, in \u001b[0;36mIndexVariable._finalize_indexing_result\u001b[0;34m(self, dims, data)\u001b[0m\n\u001b[1;32m   2684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_finalize_indexing_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, dims, data):\n\u001b[1;32m   2685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2686\u001b[0m         \u001b[38;5;66;03m# returns Variable rather than IndexVariable if multi-dimensional\u001b[39;00m\n\u001b[0;32m-> 2687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2688\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace(dims\u001b[38;5;241m=\u001b[39mdims, data\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:401\u001b[0m, in \u001b[0;36mVariable.__init__\u001b[0;34m(self, dims, data, attrs, encoding, fastpath)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     dims,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m     fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    380\u001b[0m ):\n\u001b[1;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m        unrecognized encoding items.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m--> 401\u001b[0m         dims\u001b[38;5;241m=\u001b[39mdims, data\u001b[38;5;241m=\u001b[39m\u001b[43mas_compatible_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfastpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfastpath\u001b[49m\u001b[43m)\u001b[49m, attrs\u001b[38;5;241m=\u001b[39mattrs\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:323\u001b[0m, in \u001b[0;36mas_compatible_data\u001b[0;34m(data, fastpath)\u001b[0m\n\u001b[1;32m    320\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_possibly_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_wrap_data(data)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:235\u001b[0m, in \u001b[0;36m_possibly_convert_objects\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_possibly_convert_objects\u001b[39m(values):\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert arrays of datetime.datetime and datetime.timedelta objects into\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    datetime64 and timedelta64, according to the pandas convention. For the time\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    being, convert any non-nanosecond precision DatetimeIndex or TimedeltaIndex\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    if they are not.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m     as_series \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m as_series\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    237\u001b[0m         as_series \u001b[38;5;241m=\u001b[39m _as_nanosecond_precision(as_series)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/series.py:588\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    586\u001b[0m manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 588\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mSingleBlockManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    590\u001b[0m     data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/internals/managers.py:1870\u001b[0m, in \u001b[0;36mSingleBlockManager.from_array\u001b[0;34m(cls, array, index, refs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_array\u001b[39m(\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;28mcls\u001b[39m, array: ArrayLike, index: Index, refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SingleBlockManager:\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;124;03m    Constructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1870\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_coerce_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m     bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(index)))\n\u001b[1;32m   1872\u001b[0m     block \u001b[38;5;241m=\u001b[39m new_block(array, placement\u001b[38;5;241m=\u001b[39mbp, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/internals/blocks.py:2662\u001b[0m, in \u001b[0;36mmaybe_coerce_values\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   2659\u001b[0m \u001b[38;5;66;03m# Caller is responsible for ensuring NumpyExtensionArray is already extracted.\u001b[39;00m\n\u001b[1;32m   2661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m-> 2662\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mensure_wrapped_if_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2665\u001b[0m         values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/construction.py:490\u001b[0m, in \u001b[0;36mensure_wrapped_if_datetimelike\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatetimeArray\n\u001b[1;32m    489\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m get_supported_dtype(arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatetimeArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimedeltaArray\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:327\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence\u001b[0;34m(cls, scalars, dtype, copy)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_sequence\u001b[39m(\u001b[38;5;28mcls\u001b[39m, scalars, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_sequence_not_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscalars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:362\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence_not_strict\u001b[0;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     unit \u001b[38;5;241m=\u001b[39m dtl\u001b[38;5;241m.\u001b[39mdtype_to_unit(dtype)\n\u001b[0;32m--> 362\u001b[0m data, copy \u001b[38;5;241m=\u001b[39m \u001b[43mdtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_arraylike_for_datetimelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatetimeArray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m inferred_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, DatetimeArray):\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:2454\u001b[0m, in \u001b[0;36mensure_arraylike_for_datetimelike\u001b[0;34m(data, copy, cls_name)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (np\u001b[38;5;241m.\u001b[39mndarray, ExtensionArray)):\n\u001b[1;32m   2451\u001b[0m     \u001b[38;5;66;03m# GH#24539 e.g. xarray, dask object\u001b[39;00m\n\u001b[1;32m   2452\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[0;32m-> 2454\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCCategorical\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2455\u001b[0m     \u001b[38;5;66;03m# GH#18664 preserve tz in going DTI->Categorical->DTI\u001b[39;00m\n\u001b[1;32m   2456\u001b[0m     \u001b[38;5;66;03m# TODO: cases where we need to do another pass through maybe_convert_dtype,\u001b[39;00m\n\u001b[1;32m   2457\u001b[0m     \u001b[38;5;66;03m#  e.g. the categories are timedelta64s\u001b[39;00m\n\u001b[1;32m   2458\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39mtake(data\u001b[38;5;241m.\u001b[39mcodes, fill_value\u001b[38;5;241m=\u001b[39mNaT)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   2459\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/dtypes/generic.py:42\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(inst, attr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m comp\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# error: 'classmethod' used with a non-method\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check(inst) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subclasscheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Raise instead of returning False\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# This is consistent with default __subclasscheck__ behavior\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_winds_europe = []\n",
    "for target_month, target_day in tqdm(storm_month_day):\n",
    "    # Filter Test storms\n",
    "    if ((target_month==2) & (target_day==19)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([1997]))\n",
    "    elif ((target_month==12) & (target_day==15)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([1999]))\n",
    "    elif ((target_month==2) & (target_day==25)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2002]))\n",
    "    elif ((target_month==2) & (target_day==3)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2011]))\n",
    "    elif ((target_month==2) & (target_day==1)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2016]))\n",
    "    elif ((target_month==2) & (target_day==8)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2016]))\n",
    "    elif ((target_month==2) & (target_day==16)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2020]))\n",
    "    elif ((target_month==2) & (target_day==28)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([1990]))\n",
    "    else:\n",
    "        yearin = year.copy()\n",
    "        \n",
    "    # Process the remaining years\n",
    "    for yearz in tqdm(yearin):\n",
    "        # import data\n",
    "        #u10path = upath+f'ERA5_{str(yearz)}-{str(target_month)}_10m_u_component_of_wind.nc'\n",
    "        #v10path = vpath+f'ERA5_{str(yearz)}-{str(target_month)}_10m_v_component_of_wind.nc'\n",
    "        i10fgpath = ifg+f'ERA5_{str(yearz)}-{str(target_month)}_instantaneous_10m_wind_gust.nc'\n",
    "        \n",
    "        # read files with xarray\n",
    "        #u10 = xr.open_dataset(glob.glob(u10path)[0])\n",
    "        #v10 = xr.open_dataset(glob.glob(v10path)[0])\n",
    "        i10fg = xr.open_dataset(glob.glob(i10fgpath)[0])\n",
    "\n",
    "        if target_month == 2 and target_day == 29:\n",
    "            if yearz % 4 != 0:\n",
    "                continue\n",
    "            elif yearz % 100 == 0 and yearz % 400 != 0:\n",
    "                continue\n",
    "\n",
    "        # parse date\n",
    "        first_true_index,last_true_index = data_process.parse_date_and_output_list(i10fg,target_month,target_day)\n",
    "\n",
    "        # Convert longitude from 0-360 to -180 to 180\n",
    "        #u10['longitude'] = ((u10['longitude'] + 180) % 360) - 180\n",
    "        #v10['longitude'] = ((v10['longitude'] + 180) % 360) - 180\n",
    "        i10fg['longitude'] = ((i10fg['longitude'] + 180) % 360) - 180\n",
    "        # Sort the dataset along the new longitude axis\n",
    "        #u10 = u10.sortby('longitude')\n",
    "        #v10 = v10.sortby('longitude')\n",
    "        i10fg = i10fg.sortby('longitude')\n",
    "\n",
    "        # Get the Europe subregion\n",
    "        i10fg_europe = i10fg.sel(latitude=slice(71, 30), longitude=slice(-15, 40))\n",
    "\n",
    "        # parse date\n",
    "        i10fg_europe_date = i10fg_europe.isel(time=slice(first_true_index, last_true_index + 1))\n",
    "\n",
    "        # get wind speed\n",
    "        del i10fg, i10fg_europe\n",
    "        gc.collect()\n",
    "\n",
    "        # get maximum wind for 1 year\n",
    "        #max_wind_europe = wspd.max(dim='time')\n",
    "        max_wind_europe = i10fg_europe_date.max(dim='time')\n",
    "\n",
    "        max_winds_europe.append(max_wind_europe)\n",
    "    \n",
    "    # Save the maximum wind speed for day target_day of month target_month\n",
    "    locals()['max_winds_europe_'+str(target_month)+'_'+str(target_day)] = xr.concat(max_winds_europe, dim=\"time\").max('time')\n",
    "    # Convert the dataset to a DataArray (if needed) and set CRS\n",
    "    data_array = locals()['max_winds_europe_'+str(target_month)+'_'+str(target_day)]\n",
    "    #data_array = data_array.rio.write_crs(\"EPSG:4326\")  # Assign CRS (WGS84)\n",
    "    test_cut = data_array.where(eu_final_raster['band_data'] == 1)\n",
    "    dataset_cut = test_cut\n",
    "    dataset_cut = dataset_cut.rio.write_crs(\"EPSG:4326\")  # Assign CRS (WGS84)\n",
    "    #output_path = f'data/climatology/instantaneous_10m_wind_gust_cut/{file[:-4]}_cut.tif'\n",
    "    # drop spatial_ref attribute\n",
    "    dataset_cut = dataset_cut.drop_vars('spatial_ref')\n",
    "    # convert to 2D\n",
    "    dataset_cut = dataset_cut.squeeze()\n",
    "    # Save as a raster file (GeoTIFF)\n",
    "    output_path = f\"data/climatology/daily_with_storms/{'climatology_europe_'+str(target_month)+'_'+str(target_day)}.tif\"\n",
    "    dataset_cut.rio.to_raster(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e089ac-4246-43de-86d1-6a555478509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#plt.title('Daily Max Wind Climatology: 01.02')\\n#plt.savefig('./climatology.png',dpi=400)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xr.concat(max_winds_europe, dim=\"time\").mean('time').plot()\n",
    "#test['i10fg'].plot()\n",
    "for target_month, target_day in storm_month_day:\n",
    "    ds = locals()['max_winds_europe_'+str(target_month)+'_'+str(target_day)]\n",
    "    # Convert the dataset to a DataArray (if needed) and set CRS\n",
    "    data_array = ds['i10fg']\n",
    "    data_array = data_array.rio.write_crs(\"EPSG:4326\")  # Assign CRS (WGS84)\n",
    "\n",
    "    # Save as a raster file (GeoTIFF)\n",
    "    output_path = f\"data/climatology/daily_without_storms/{'climatology_europe_'+str(target_month)+'_'+str(target_day)}.tif\"\n",
    "    data_array.rio.to_raster(output_path)\n",
    "'''\n",
    "#plt.title('Daily Max Wind Climatology: 01.02')\n",
    "#plt.savefig('./climatology.png',dpi=400)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2410ccd",
   "metadata": {},
   "source": [
    "# part for daily max WITH storms included (except test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0d7b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:40<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:45<00:00,  1.48s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.35s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:40<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:48<00:00,  1.56s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [01:05<00:00,  2.18s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:47<00:00,  1.52s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.57s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:53<00:00,  1.72s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:50<00:00,  1.63s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:47<00:00,  1.60s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:47<00:00,  1.58s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:40<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:10<00:00,  3.04it/s]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.45s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.35s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.37s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 59/59 [42:28<00:00, 43.20s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Load time series dataset\n",
    "dates = pd.read_csv('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/data/time_series_1h_EU/instantaneous_10m_wind_gust/instantaneous_10m_wind_gust_max.csv')['start_date']\n",
    "\n",
    "# Load and preprocess the raster dataset\n",
    "eu_final_raster = xr.open_dataset('pre_processing/maps/eu_final_raster.tif', engine='rasterio').rename({'x': 'longitude', 'y': 'latitude'})\n",
    "\n",
    "# Parse storm dates\n",
    "storm_dates = [datetime.strptime(date, '%Y-%m-%dT%H:%M:%S') for date in dates]\n",
    "\n",
    "# Extract unique month-day combinations\n",
    "storm_month_day = np.unique([[date.month, date.day] for date in storm_dates], axis=0)\n",
    "\n",
    "# Define special exclusions for years based on month and day\n",
    "exclusions = {\n",
    "    (2, 19): [1997],\n",
    "    (12, 15): [1999],\n",
    "    (2, 25): [2002],\n",
    "    (2, 3): [2011],\n",
    "    (2, 1): [2016],\n",
    "    (2, 8): [2016],\n",
    "    (2, 16): [2020],\n",
    "    (2, 28): [1990],\n",
    "}\n",
    "\n",
    "# Process each unique storm day\n",
    "for target_month, target_day in tqdm(storm_month_day):\n",
    "    yearin = np.setdiff1d(year, exclusions.get((target_month, target_day), []))\n",
    "\n",
    "    max_winds_europe = []\n",
    "    for yearz in tqdm(yearin):\n",
    "        # Skip non-leap years for Feb 29\n",
    "        if target_month == 2 and target_day == 29 and (yearz % 4 != 0 or (yearz % 100 == 0 and yearz % 400 != 0)):\n",
    "            continue\n",
    "\n",
    "        # Load dataset\n",
    "        i10fgpath = f'{ifg}ERA5_{yearz}-{target_month}_instantaneous_10m_wind_gust.nc'\n",
    "        i10fg = xr.open_dataset(glob.glob(i10fgpath)[0])\n",
    "\n",
    "        # Parse date indices\n",
    "        first_true_index, last_true_index = data_process.parse_date_and_output_list(i10fg, target_month, target_day)\n",
    "\n",
    "        # Preprocess dataset\n",
    "        i10fg['longitude'] = ((i10fg['longitude'] + 180) % 360) - 180\n",
    "        i10fg = i10fg.sortby('longitude')\n",
    "        i10fg_europe = i10fg.sel(latitude=slice(71, 30), longitude=slice(-15, 40))\n",
    "        i10fg_europe_date = i10fg_europe.isel(time=slice(first_true_index, last_true_index + 1))\n",
    "\n",
    "        # Calculate maximum wind speed\n",
    "        max_wind_europe = i10fg_europe_date.max(dim='time')\n",
    "        max_winds_europe.append(max_wind_europe)\n",
    "\n",
    "        del i10fg, i10fg_europe\n",
    "        gc.collect()\n",
    "\n",
    "    # Combine and save results\n",
    "    combined_max = xr.concat(max_winds_europe, dim=\"time\").max('time')\n",
    "    dataset_cut = combined_max.where(eu_final_raster['band_data'] == 1).rio.write_crs(\"EPSG:4326\").squeeze().drop_vars('spatial_ref')\n",
    "\n",
    "    output_path = f\"data/climatology/daily_with_storms/climatology_europe_{target_month}_{target_day}.tif\"\n",
    "    dataset_cut.rio.to_raster(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670fe31",
   "metadata": {},
   "source": [
    "# part for daily max WITHOUT storms included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6cbb345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.57s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.56s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.31s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.35s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:38<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:41<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.35s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:38<00:00,  1.30s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:41<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:42<00:00,  1.48s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.31s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:40<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:40<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.32it/s]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:44<00:00,  1.50s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:45<00:00,  1.51s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:44<00:00,  1.47s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:39<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.41s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.41s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.45s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:44<00:00,  1.49s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:45<00:00,  1.50s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.46s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:44<00:00,  1.49s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:45<00:00,  1.53s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:48<00:00,  1.62s/it]\n",
      "100%|█████████████████████████████████████████████████| 27/27 [00:43<00:00,  1.62s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:47<00:00,  1.59s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.53s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.37s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:47<00:00,  1.57s/it]\n",
      "100%|█████████████████████████████████████████████████| 28/28 [00:38<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 28/28 [00:39<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:40<00:00,  1.41s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:41<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 59/59 [41:04<00:00, 41.78s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Load time series dataset\n",
    "dates = pd.read_csv('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/data/time_series_1h_EU/instantaneous_10m_wind_gust/instantaneous_10m_wind_gust_max.csv')['start_date']\n",
    "\n",
    "# Load and preprocess the raster dataset\n",
    "eu_final_raster = xr.open_dataset('pre_processing/maps/eu_final_raster.tif', engine='rasterio').rename({'x': 'longitude', 'y': 'latitude'})\n",
    "\n",
    "# Parse storm dates\n",
    "storm_dates = [datetime.strptime(date, '%Y-%m-%dT%H:%M:%S') for date in dates]\n",
    "\n",
    "# Extract unique month-day combinations with landfall years\n",
    "storm_month_day_year = [[date.month, date.day, date.year] for date in storm_dates]\n",
    "storm_month_day = np.unique([[mdy[0], mdy[1]] for mdy in storm_month_day_year], axis=0)\n",
    "\n",
    "# Define special exclusions for specific years based on month and day\n",
    "exclusions = {\n",
    "    (2, 19): [1997],\n",
    "    (12, 15): [1999],\n",
    "    (2, 25): [2002],\n",
    "    (2, 3): [2011],\n",
    "    (2, 1): [2016],\n",
    "    (2, 8): [2016],\n",
    "    (2, 16): [2020],\n",
    "    (2, 28): [1990],\n",
    "}\n",
    "\n",
    "# Process each unique storm day\n",
    "for target_month, target_day in tqdm(storm_month_day):\n",
    "    # Identify landfall year(s) for the current month-day combination\n",
    "    landfall_years = [mdy[2] for mdy in storm_month_day_year if mdy[0] == target_month and mdy[1] == target_day]\n",
    "    excluded_years = exclusions.get((target_month, target_day), []) + landfall_years\n",
    "    yearin = np.setdiff1d(year, excluded_years)\n",
    "\n",
    "    max_winds_europe = []\n",
    "    for yearz in tqdm(yearin):\n",
    "        # Skip non-leap years for Feb 29\n",
    "        if target_month == 2 and target_day == 29 and (yearz % 4 != 0 or (yearz % 100 == 0 and yearz % 400 != 0)):\n",
    "            continue\n",
    "\n",
    "        # Load dataset\n",
    "        i10fgpath = f'{ifg}ERA5_{yearz}-{target_month}_instantaneous_10m_wind_gust.nc'\n",
    "        i10fg = xr.open_dataset(glob.glob(i10fgpath)[0])\n",
    "\n",
    "        # Parse date indices\n",
    "        first_true_index, last_true_index = data_process.parse_date_and_output_list(i10fg, target_month, target_day)\n",
    "\n",
    "        # Preprocess dataset\n",
    "        i10fg['longitude'] = ((i10fg['longitude'] + 180) % 360) - 180\n",
    "        i10fg = i10fg.sortby('longitude')\n",
    "        i10fg_europe = i10fg.sel(latitude=slice(71, 30), longitude=slice(-15, 40))\n",
    "        i10fg_europe_date = i10fg_europe.isel(time=slice(first_true_index, last_true_index + 1))\n",
    "\n",
    "        # Calculate maximum wind speed\n",
    "        max_wind_europe = i10fg_europe_date.max(dim='time')\n",
    "        max_winds_europe.append(max_wind_europe)\n",
    "\n",
    "        del i10fg, i10fg_europe\n",
    "        gc.collect()\n",
    "\n",
    "    # Combine and save results\n",
    "    combined_max = xr.concat(max_winds_europe, dim=\"time\").max('time')\n",
    "    dataset_cut = combined_max.where(eu_final_raster['band_data'] == 1).rio.write_crs(\"EPSG:4326\").squeeze().drop_vars('spatial_ref')\n",
    "\n",
    "    output_path = f\"data/climatology/daily_without_storms/climatology_europe_{target_month}_{target_day}.tif\"\n",
    "    dataset_cut.rio.to_raster(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
