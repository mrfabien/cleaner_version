{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49cd137-6bdf-4716-9a49-1e1e84a5a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librairies\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the path to the custom library\n",
    "custom_library_path = os.path.abspath('/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/fabienVED')\n",
    "sys.path.append(custom_library_path)\n",
    "# set the directory path\n",
    "os.chdir('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/')\n",
    "\n",
    "\n",
    "import data_process\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a5859e-0a9d-4694-a016-d333efcbb498",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4465c1e9-3048-4345-921f-79d049c24850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "#upath = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5/SL/10m_u_component_of_wind/'\n",
    "#vpath = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5/SL/10m_v_component_of_wind/'\n",
    "ifg = '/work/FAC/FGSE/IDYST/tbeucler/default/raw_data/ECMWF/ERA5/SL/instantaneous_10m_wind_gust/'\n",
    "\n",
    "# Date specification\n",
    "year = np.arange(1990,2021,1)\n",
    "#target_month = 2\n",
    "#target_day = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2277b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gather all the starting days of the 96 storms from the time series datasets\n",
    "\n",
    "# Load the time series datasets\n",
    "\n",
    "dates = pd.read_csv('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/data/time_series_1h_EU/instantaneous_10m_wind_gust/instantaneous_10m_wind_gust_max.csv')\n",
    "dates = dates['start_date']\n",
    "eu_final_raster = xr.open_dataset('pre_processing/maps/eu_final_raster.tif',\n",
    "                                    engine='rasterio')\n",
    "\n",
    "# rename x and y to lon and lat\n",
    "eu_final_raster = eu_final_raster.rename({'x':'longitude','y':'latitude'})\n",
    "\n",
    "# Extract the starting days of the 96 storms\n",
    "\n",
    "storm_dates = []\n",
    "for date in dates:\n",
    "    storm_dates.append(datetime.strptime(date, '%Y-%m-%dT%H:%M:%S'))\n",
    "\n",
    "# Extract each month and day of the storm starting days\n",
    "\n",
    "storm_year = []\n",
    "storm_month = []\n",
    "storm_day = []\n",
    "for date in storm_dates:\n",
    "    storm_year.append(date.year)\n",
    "    storm_month.append(date.month)\n",
    "    storm_day.append(date.day)\n",
    "\n",
    "# Combine the month and day of the storm starting days into a single list\n",
    "\n",
    "storm_year_month_day = []\n",
    "storm_month_day = []\n",
    "for i in range(len(storm_month)):\n",
    "    storm_year_month_day.append([storm_year[i],storm_month[i], storm_day[i]])\n",
    "    storm_month_day.append([storm_month[i], storm_day[i]])\n",
    "\n",
    "# keep the only the days that don't repeat themselves\n",
    "storm_month_day = np.array(storm_month_day)\n",
    "storm_month_day = np.unique(storm_month_day, axis=0)\n",
    "\n",
    "storm_year_month_day = np.array(storm_year_month_day)\n",
    "storm_year_month_day = np.unique(storm_year_month_day, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93f25bf-88e8-4452-bcd7-bfded9ecc742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 31/31 [00:45<00:00,  1.46s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:40<00:00,  1.30s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.37s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:48<00:00,  1.56s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.35s/it]\n",
      " 35%|█████████████████▍                               | 11/31 [00:16<00:29,  1.48s/it]\n",
      " 19%|█████████▏                                       | 11/59 [08:14<35:59, 44.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# parse date\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m first_true_index,last_true_index \u001b[38;5;241m=\u001b[39m \u001b[43mdata_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_date_and_output_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi10fg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_month\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_day\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Convert longitude from 0-360 to -180 to 180\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#u10['longitude'] = ((u10['longitude'] + 180) % 360) - 180\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#v10['longitude'] = ((v10['longitude'] + 180) % 360) - 180\u001b[39;00m\n\u001b[1;32m     47\u001b[0m i10fg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ((i10fg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m180\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m360\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m180\u001b[39m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/fabienVED/data_process.py:11\u001b[0m, in \u001b[0;36mparse_date_and_output_list\u001b[0;34m(u10, target_month, target_day)\u001b[0m\n\u001b[1;32m      9\u001b[0m date_ctrl \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(u10[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m---> 11\u001b[0m     tempdate \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;28mstr\u001b[39m(\u001b[43mu10\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdata), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS.\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m000\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((tempdate\u001b[38;5;241m.\u001b[39mmonth\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mint\u001b[39m(target_month)) \u001b[38;5;241m&\u001b[39m (tempdate\u001b[38;5;241m.\u001b[39mday\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mint\u001b[39m(target_day))):\n\u001b[1;32m     13\u001b[0m         date_ctrl\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/dataarray.py:899\u001b[0m, in \u001b[0;36mDataArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_coord(key)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# xarray-style array indexing\u001b[39;00m\n\u001b[0;32m--> 899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_item_key_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/dataarray.py:1547\u001b[0m, in \u001b[0;36mDataArray.isel\u001b[0;34m(self, indexers, drop, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m coord_indexers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1544\u001b[0m     k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m indexers\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m coord_value\u001b[38;5;241m.\u001b[39mdims\n\u001b[1;32m   1545\u001b[0m }\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coord_indexers:\n\u001b[0;32m-> 1547\u001b[0m     coord_value \u001b[38;5;241m=\u001b[39m \u001b[43mcoord_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoord_indexers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop \u001b[38;5;129;01mand\u001b[39;00m coord_value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1549\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:1038\u001b[0m, in \u001b[0;36mVariable.isel\u001b[0;34m(self, indexers, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m indexers \u001b[38;5;241m=\u001b[39m drop_dims_from_indexers(indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims, missing_dims)\n\u001b[1;32m   1037\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(indexers\u001b[38;5;241m.\u001b[39mget(dim, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims)\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:809\u001b[0m, in \u001b[0;36mVariable.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_order:\n\u001b[1;32m    808\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(data, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(new_order)), new_order)\n\u001b[0;32m--> 809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finalize_indexing_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:2687\u001b[0m, in \u001b[0;36mIndexVariable._finalize_indexing_result\u001b[0;34m(self, dims, data)\u001b[0m\n\u001b[1;32m   2684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_finalize_indexing_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, dims, data):\n\u001b[1;32m   2685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2686\u001b[0m         \u001b[38;5;66;03m# returns Variable rather than IndexVariable if multi-dimensional\u001b[39;00m\n\u001b[0;32m-> 2687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2688\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace(dims\u001b[38;5;241m=\u001b[39mdims, data\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:401\u001b[0m, in \u001b[0;36mVariable.__init__\u001b[0;34m(self, dims, data, attrs, encoding, fastpath)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     dims,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m     fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    380\u001b[0m ):\n\u001b[1;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m        unrecognized encoding items.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m--> 401\u001b[0m         dims\u001b[38;5;241m=\u001b[39mdims, data\u001b[38;5;241m=\u001b[39m\u001b[43mas_compatible_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfastpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfastpath\u001b[49m\u001b[43m)\u001b[49m, attrs\u001b[38;5;241m=\u001b[39mattrs\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:323\u001b[0m, in \u001b[0;36mas_compatible_data\u001b[0;34m(data, fastpath)\u001b[0m\n\u001b[1;32m    320\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_possibly_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_wrap_data(data)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:235\u001b[0m, in \u001b[0;36m_possibly_convert_objects\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_possibly_convert_objects\u001b[39m(values):\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert arrays of datetime.datetime and datetime.timedelta objects into\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    datetime64 and timedelta64, according to the pandas convention. For the time\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    being, convert any non-nanosecond precision DatetimeIndex or TimedeltaIndex\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    if they are not.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m     as_series \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m as_series\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    237\u001b[0m         as_series \u001b[38;5;241m=\u001b[39m _as_nanosecond_precision(as_series)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/series.py:588\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    586\u001b[0m manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 588\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mSingleBlockManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    590\u001b[0m     data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/internals/managers.py:1870\u001b[0m, in \u001b[0;36mSingleBlockManager.from_array\u001b[0;34m(cls, array, index, refs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_array\u001b[39m(\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;28mcls\u001b[39m, array: ArrayLike, index: Index, refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SingleBlockManager:\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;124;03m    Constructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1870\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_coerce_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m     bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(index)))\n\u001b[1;32m   1872\u001b[0m     block \u001b[38;5;241m=\u001b[39m new_block(array, placement\u001b[38;5;241m=\u001b[39mbp, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/internals/blocks.py:2662\u001b[0m, in \u001b[0;36mmaybe_coerce_values\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   2659\u001b[0m \u001b[38;5;66;03m# Caller is responsible for ensuring NumpyExtensionArray is already extracted.\u001b[39;00m\n\u001b[1;32m   2661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m-> 2662\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mensure_wrapped_if_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2665\u001b[0m         values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/construction.py:490\u001b[0m, in \u001b[0;36mensure_wrapped_if_datetimelike\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatetimeArray\n\u001b[1;32m    489\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m get_supported_dtype(arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatetimeArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimedeltaArray\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:327\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence\u001b[0;34m(cls, scalars, dtype, copy)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_sequence\u001b[39m(\u001b[38;5;28mcls\u001b[39m, scalars, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_sequence_not_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscalars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:362\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence_not_strict\u001b[0;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     unit \u001b[38;5;241m=\u001b[39m dtl\u001b[38;5;241m.\u001b[39mdtype_to_unit(dtype)\n\u001b[0;32m--> 362\u001b[0m data, copy \u001b[38;5;241m=\u001b[39m \u001b[43mdtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_arraylike_for_datetimelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatetimeArray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m inferred_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, DatetimeArray):\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:2454\u001b[0m, in \u001b[0;36mensure_arraylike_for_datetimelike\u001b[0;34m(data, copy, cls_name)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (np\u001b[38;5;241m.\u001b[39mndarray, ExtensionArray)):\n\u001b[1;32m   2451\u001b[0m     \u001b[38;5;66;03m# GH#24539 e.g. xarray, dask object\u001b[39;00m\n\u001b[1;32m   2452\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[0;32m-> 2454\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCCategorical\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2455\u001b[0m     \u001b[38;5;66;03m# GH#18664 preserve tz in going DTI->Categorical->DTI\u001b[39;00m\n\u001b[1;32m   2456\u001b[0m     \u001b[38;5;66;03m# TODO: cases where we need to do another pass through maybe_convert_dtype,\u001b[39;00m\n\u001b[1;32m   2457\u001b[0m     \u001b[38;5;66;03m#  e.g. the categories are timedelta64s\u001b[39;00m\n\u001b[1;32m   2458\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39mtake(data\u001b[38;5;241m.\u001b[39mcodes, fill_value\u001b[38;5;241m=\u001b[39mNaT)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   2459\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/pandas/core/dtypes/generic.py:42\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(inst, attr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m comp\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# error: 'classmethod' used with a non-method\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check(inst) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subclasscheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Raise instead of returning False\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# This is consistent with default __subclasscheck__ behavior\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_winds_europe = []\n",
    "for target_month, target_day in tqdm(storm_month_day):\n",
    "    # Filter Test storms\n",
    "    if ((target_month==2) & (target_day==19)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([1997]))\n",
    "    elif ((target_month==12) & (target_day==15)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([1999]))\n",
    "    elif ((target_month==2) & (target_day==25)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2002]))\n",
    "    elif ((target_month==2) & (target_day==3)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2011]))\n",
    "    elif ((target_month==2) & (target_day==1)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2016]))\n",
    "    elif ((target_month==2) & (target_day==8)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2016]))\n",
    "    elif ((target_month==2) & (target_day==16)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([2020]))\n",
    "    elif ((target_month==2) & (target_day==28)):\n",
    "        yearin = np.setdiff1d(year,np.asarray([1990]))\n",
    "    else:\n",
    "        yearin = year.copy()\n",
    "        \n",
    "    # Process the remaining years\n",
    "    for yearz in tqdm(yearin):\n",
    "        # import data\n",
    "        #u10path = upath+f'ERA5_{str(yearz)}-{str(target_month)}_10m_u_component_of_wind.nc'\n",
    "        #v10path = vpath+f'ERA5_{str(yearz)}-{str(target_month)}_10m_v_component_of_wind.nc'\n",
    "        i10fgpath = ifg+f'ERA5_{str(yearz)}-{str(target_month)}_instantaneous_10m_wind_gust.nc'\n",
    "        \n",
    "        # read files with xarray\n",
    "        #u10 = xr.open_dataset(glob.glob(u10path)[0])\n",
    "        #v10 = xr.open_dataset(glob.glob(v10path)[0])\n",
    "        i10fg = xr.open_dataset(glob.glob(i10fgpath)[0])\n",
    "\n",
    "        if target_month == 2 and target_day == 29:\n",
    "            if yearz % 4 != 0:\n",
    "                continue\n",
    "            elif yearz % 100 == 0 and yearz % 400 != 0:\n",
    "                continue\n",
    "\n",
    "        # parse date\n",
    "        first_true_index,last_true_index = data_process.parse_date_and_output_list(i10fg,target_month,target_day)\n",
    "\n",
    "        # Convert longitude from 0-360 to -180 to 180\n",
    "        #u10['longitude'] = ((u10['longitude'] + 180) % 360) - 180\n",
    "        #v10['longitude'] = ((v10['longitude'] + 180) % 360) - 180\n",
    "        i10fg['longitude'] = ((i10fg['longitude'] + 180) % 360) - 180\n",
    "        # Sort the dataset along the new longitude axis\n",
    "        #u10 = u10.sortby('longitude')\n",
    "        #v10 = v10.sortby('longitude')\n",
    "        i10fg = i10fg.sortby('longitude')\n",
    "\n",
    "        # Get the Europe subregion\n",
    "        i10fg_europe = i10fg.sel(latitude=slice(71, 30), longitude=slice(-15, 40))\n",
    "\n",
    "        # parse date\n",
    "        i10fg_europe_date = i10fg_europe.isel(time=slice(first_true_index, last_true_index + 1))\n",
    "\n",
    "        # get wind speed\n",
    "        del i10fg, i10fg_europe\n",
    "        gc.collect()\n",
    "\n",
    "        # get maximum wind for 1 year\n",
    "        #max_wind_europe = wspd.max(dim='time')\n",
    "        max_wind_europe = i10fg_europe_date.max(dim='time')\n",
    "\n",
    "        max_winds_europe.append(max_wind_europe)\n",
    "    \n",
    "    # Save the maximum wind speed for day target_day of month target_month\n",
    "    locals()['max_winds_europe_'+str(target_month)+'_'+str(target_day)] = xr.concat(max_winds_europe, dim=\"time\").max('time')\n",
    "    # Convert the dataset to a DataArray (if needed) and set CRS\n",
    "    data_array = locals()['max_winds_europe_'+str(target_month)+'_'+str(target_day)]\n",
    "    #data_array = data_array.rio.write_crs(\"EPSG:4326\")  # Assign CRS (WGS84)\n",
    "    test_cut = data_array.where(eu_final_raster['band_data'] == 1)\n",
    "    dataset_cut = test_cut\n",
    "    dataset_cut = dataset_cut.rio.write_crs(\"EPSG:4326\")  # Assign CRS (WGS84)\n",
    "    #output_path = f'data/climatology/instantaneous_10m_wind_gust_cut/{file[:-4]}_cut.tif'\n",
    "    # drop spatial_ref attribute\n",
    "    dataset_cut = dataset_cut.drop_vars('spatial_ref')\n",
    "    # convert to 2D\n",
    "    dataset_cut = dataset_cut.squeeze()\n",
    "    # Save as a raster file (GeoTIFF)\n",
    "    output_path = f\"data/climatology/daily_with_storms/{'climatology_europe_'+str(target_month)+'_'+str(target_day)}.tif\"\n",
    "    dataset_cut.rio.to_raster(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e089ac-4246-43de-86d1-6a555478509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#plt.title('Daily Max Wind Climatology: 01.02')\\n#plt.savefig('./climatology.png',dpi=400)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xr.concat(max_winds_europe, dim=\"time\").mean('time').plot()\n",
    "#test['i10fg'].plot()\n",
    "for target_month, target_day in storm_month_day:\n",
    "    ds = locals()['max_winds_europe_'+str(target_month)+'_'+str(target_day)]\n",
    "    # Convert the dataset to a DataArray (if needed) and set CRS\n",
    "    data_array = ds['i10fg']\n",
    "    data_array = data_array.rio.write_crs(\"EPSG:4326\")  # Assign CRS (WGS84)\n",
    "\n",
    "    # Save as a raster file (GeoTIFF)\n",
    "    output_path = f\"data/climatology/daily_without_storms/{'climatology_europe_'+str(target_month)+'_'+str(target_day)}.tif\"\n",
    "    data_array.rio.to_raster(output_path)\n",
    "'''\n",
    "#plt.title('Daily Max Wind Climatology: 01.02')\n",
    "#plt.savefig('./climatology.png',dpi=400)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2410ccd",
   "metadata": {},
   "source": [
    "# part for daily max WITH storms included (except test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0d7b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:40<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:45<00:00,  1.48s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.35s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:40<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:48<00:00,  1.56s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [01:05<00:00,  2.18s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:47<00:00,  1.52s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.57s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:53<00:00,  1.72s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:50<00:00,  1.63s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:47<00:00,  1.60s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:47<00:00,  1.58s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:40<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:10<00:00,  3.04it/s]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.45s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:44<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.35s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:43<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:41<00:00,  1.34s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.37s/it]\n",
      "100%|█████████████████████████████████████████████████| 31/31 [00:42<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 59/59 [42:28<00:00, 43.20s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Load time series dataset\n",
    "dates = pd.read_csv('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/data/time_series_1h_EU/instantaneous_10m_wind_gust/instantaneous_10m_wind_gust_max.csv')['start_date']\n",
    "\n",
    "# Load and preprocess the raster dataset\n",
    "eu_final_raster = xr.open_dataset('pre_processing/maps/eu_final_raster.tif', engine='rasterio').rename({'x': 'longitude', 'y': 'latitude'})\n",
    "\n",
    "# Parse storm dates\n",
    "storm_dates = [datetime.strptime(date, '%Y-%m-%dT%H:%M:%S') for date in dates]\n",
    "\n",
    "# Extract unique month-day combinations\n",
    "storm_month_day = np.unique([[date.month, date.day] for date in storm_dates], axis=0)\n",
    "\n",
    "# Define special exclusions for years based on month and day\n",
    "exclusions = {\n",
    "    (2, 19): [1997],\n",
    "    (12, 15): [1999],\n",
    "    (2, 25): [2002],\n",
    "    (2, 3): [2011],\n",
    "    (2, 1): [2016],\n",
    "    (2, 8): [2016],\n",
    "    (2, 16): [2020],\n",
    "    (2, 28): [1990],\n",
    "}\n",
    "\n",
    "# Process each unique storm day\n",
    "for target_month, target_day in tqdm(storm_month_day):\n",
    "    yearin = np.setdiff1d(year, exclusions.get((target_month, target_day), []))\n",
    "\n",
    "    max_winds_europe = []\n",
    "    for yearz in tqdm(yearin):\n",
    "        # Skip non-leap years for Feb 29\n",
    "        if target_month == 2 and target_day == 29 and (yearz % 4 != 0 or (yearz % 100 == 0 and yearz % 400 != 0)):\n",
    "            continue\n",
    "\n",
    "        # Load dataset\n",
    "        i10fgpath = f'{ifg}ERA5_{yearz}-{target_month}_instantaneous_10m_wind_gust.nc'\n",
    "        i10fg = xr.open_dataset(glob.glob(i10fgpath)[0])\n",
    "\n",
    "        # Parse date indices\n",
    "        first_true_index, last_true_index = data_process.parse_date_and_output_list(i10fg, target_month, target_day)\n",
    "\n",
    "        # Preprocess dataset\n",
    "        i10fg['longitude'] = ((i10fg['longitude'] + 180) % 360) - 180\n",
    "        i10fg = i10fg.sortby('longitude')\n",
    "        i10fg_europe = i10fg.sel(latitude=slice(71, 30), longitude=slice(-15, 40))\n",
    "        i10fg_europe_date = i10fg_europe.isel(time=slice(first_true_index, last_true_index + 1))\n",
    "\n",
    "        # Calculate maximum wind speed\n",
    "        max_wind_europe = i10fg_europe_date.max(dim='time')\n",
    "        max_winds_europe.append(max_wind_europe)\n",
    "\n",
    "        del i10fg, i10fg_europe\n",
    "        gc.collect()\n",
    "\n",
    "    # Combine and save results\n",
    "    combined_max = xr.concat(max_winds_europe, dim=\"time\").max('time')\n",
    "    dataset_cut = combined_max.where(eu_final_raster['band_data'] == 1).rio.write_crs(\"EPSG:4326\").squeeze().drop_vars('spatial_ref')\n",
    "\n",
    "    output_path = f\"data/climatology/daily_with_storms/climatology_europe_{target_month}_{target_day}.tif\"\n",
    "    dataset_cut.rio.to_raster(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742b726",
   "metadata": {},
   "source": [
    "# Part for daily max WITHOUT storms included, with 1 day before and after done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8e6e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                  | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:59<00:00,  4.12s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:50<00:00,  3.82s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:54<00:00,  3.95s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 29/29 [01:55<00:00,  3.97s/it]           | 3/59 [05:45<1:46:55, 114.55s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 29/29 [01:52<00:00,  3.88s/it]           | 4/59 [07:40<1:45:13, 114.79s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 29/29 [01:53<00:00,  3.93s/it]           | 5/59 [09:32<1:42:33, 113.95s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 29/29 [01:58<00:00,  4.08s/it]           | 6/59 [11:26<1:40:40, 113.98s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 28/28 [01:52<00:00,  4.00s/it]           | 7/59 [13:25<1:40:00, 115.39s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 28/28 [01:50<00:00,  3.93s/it]           | 8/59 [15:17<1:37:10, 114.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 28/28 [01:51<00:00,  3.98s/it]           | 9/59 [17:07<1:34:11, 113.03s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 29/29 [01:56<00:00,  4.02s/it]          | 10/59 [18:58<1:31:54, 112.54s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 29/29 [01:55<00:00,  3.97s/it]          | 11/59 [20:55<1:31:03, 113.83s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 28/28 [01:50<00:00,  3.96s/it]          | 12/59 [22:50<1:29:30, 114.26s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 27/27 [01:44<00:00,  3.88s/it]          | 13/59 [24:41<1:26:48, 113.23s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 28/28 [01:49<00:00,  3.92s/it]          | 14/59 [26:26<1:23:01, 110.70s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 28/28 [01:49<00:00,  3.92s/it]          | 15/59 [28:16<1:20:57, 110.41s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 27/27 [01:46<00:00,  3.93s/it]          | 16/59 [30:06<1:19:01, 110.26s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 28/28 [01:48<00:00,  3.86s/it]          | 17/59 [31:52<1:16:19, 109.03s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 29/29 [01:53<00:00,  3.92s/it]          | 18/59 [33:40<1:14:19, 108.76s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 29/29 [01:54<00:00,  3.96s/it]          | 19/59 [35:34<1:13:29, 110.23s/it]\n",
      "100%|████████████████████████████████████████████| 30/30 [01:57<00:00,  3.90s/it]                                          | 20/59 [37:28<1:12:33, 111.63s/it]\n",
      "100%|████████████████████████████████████████████| 29/29 [02:01<00:00,  4.19s/it]                                          | 21/59 [39:26<1:11:45, 113.30s/it]\n",
      "100%|████████████████████████████████████████████| 28/28 [01:50<00:00,  3.96s/it]                                          | 22/59 [41:27<1:11:24, 115.79s/it]\n",
      " 59%|█████████████████████████▊                  | 17/29 [01:05<00:46,  3.87s/it]                                          | 23/59 [43:18<1:08:34, 114.29s/it]\n",
      " 39%|██████████████████████████████████████████████                                                                        | 23/59 [44:24<1:09:30, 115.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m i10fg_europe_date \u001b[38;5;241m=\u001b[39m i10fg_europe\u001b[38;5;241m.\u001b[39misel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(first_true_index, last_true_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Calculate maximum wind speed\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m max_wind_europe \u001b[38;5;241m=\u001b[39m \u001b[43mi10fg_europe_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m max_winds_europe\u001b[38;5;241m.\u001b[39mappend(max_wind_europe)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m i10fg, i10fg_europe\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/_aggregations.py:331\u001b[0m, in \u001b[0;36mDatasetAggregations.max\u001b[0;34m(self, dim, skipna, keep_attrs, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    255\u001b[0m     dim: Dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    260\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    Reduce this Dataset's data by applying ``max`` along some dimension(s).\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m        da       float64 8B nan\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mduck_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/dataset.py:7012\u001b[0m, in \u001b[0;36mDataset.reduce\u001b[0;34m(self, func, dim, keep_attrs, keepdims, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6992\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6993\u001b[0m             \u001b[38;5;66;03m# Some reduction functions (e.g. std, var) need to run on variables\u001b[39;00m\n\u001b[1;32m   6994\u001b[0m             \u001b[38;5;66;03m# that don't have the reduce dims: PR5393\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7005\u001b[0m             \u001b[38;5;66;03m# the former is often more efficient\u001b[39;00m\n\u001b[1;32m   7006\u001b[0m             \u001b[38;5;66;03m# keep single-element dims as list, to support Hashables\u001b[39;00m\n\u001b[1;32m   7007\u001b[0m             reduce_maybe_single \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   7008\u001b[0m                 \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   7009\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(reduce_dims) \u001b[38;5;241m==\u001b[39m var\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01mand\u001b[39;00m var\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   7010\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m reduce_dims\n\u001b[1;32m   7011\u001b[0m             )\n\u001b[0;32m-> 7012\u001b[0m             variables[name] \u001b[38;5;241m=\u001b[39m \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7013\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7014\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_maybe_single\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7015\u001b[0m \u001b[43m                \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7016\u001b[0m \u001b[43m                \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7017\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7018\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7020\u001b[0m coord_names \u001b[38;5;241m=\u001b[39m {k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m variables}\n\u001b[1;32m   7021\u001b[0m indexes \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indexes\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m variables}\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:1666\u001b[0m, in \u001b[0;36mVariable.reduce\u001b[0;34m(self, func, dim, axis, keep_attrs, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m keep_attrs_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1660\u001b[0m     _get_keep_attrs(default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m keep_attrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m keep_attrs\n\u001b[1;32m   1661\u001b[0m )\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;66;03m# Note that the call order for Variable.mean is\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;66;03m#    Variable.mean -> NamedArray.mean -> Variable.reduce\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;66;03m#    -> NamedArray.reduce\u001b[39;00m\n\u001b[0;32m-> 1666\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;66;03m# return Variable always to support IndexVariable\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Variable(\n\u001b[1;32m   1672\u001b[0m     result\u001b[38;5;241m.\u001b[39mdims, result\u001b[38;5;241m.\u001b[39m_data, attrs\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;28;01mif\u001b[39;00m keep_attrs_ \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1673\u001b[0m )\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/namedarray/core.py:910\u001b[0m, in \u001b[0;36mNamedArray.reduce\u001b[0;34m(self, func, dim, axis, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(axis, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axis) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# unpack axis for the benefit of functions\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# like np.argmin which can't handle tuple arguments\u001b[39;00m\n\u001b[1;32m    909\u001b[0m         axis \u001b[38;5;241m=\u001b[39m axis[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 910\u001b[0m     data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/variable.py:451\u001b[0m, in \u001b[0;36mVariable.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, indexing\u001b[38;5;241m.\u001b[39mExplicitlyIndexed):\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/indexing.py:837\u001b[0m, in \u001b[0;36mMemoryCachedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 837\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/indexing.py:831\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 831\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/indexing.py:788\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/indexing.py:658\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n\u001b[0;32m--> 658\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrap_numpy_scalars(array)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/coding/variables.py:81\u001b[0m, in \u001b[0;36m_ElementwiseFunctionArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/coding/variables.py:81\u001b[0m, in \u001b[0;36m_ElementwiseFunctionArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/indexing.py:651\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m     array \u001b[38;5;241m=\u001b[39m apply_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:100\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexingSupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOUTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/core/indexing.py:1015\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m-> 1015\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m     indexable \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(result)\n",
      "File \u001b[0;32m/work/FAC/FGSE/IDYST/tbeucler/default/fabien/conda_env/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:113\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    112\u001b[0m         original_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 113\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Catch IndexError in netCDF4 and return a more informative\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# error message.  This is most often called when an unsorted\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# indexer is used before the data is loaded from disk.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indexing operation you are attempting to perform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not valid on netCDF4.Variable object. Try loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data into memory first by calling .load().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Load time series dataset\n",
    "dates = pd.read_csv('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/data/time_series_1h_EU/instantaneous_10m_wind_gust/instantaneous_10m_wind_gust_max.csv')['start_date']\n",
    "\n",
    "# Load and preprocess the raster dataset\n",
    "eu_final_raster = xr.open_dataset('pre_processing/maps/eu_final_raster.tif', engine='rasterio').rename({'x': 'longitude', 'y': 'latitude'})\n",
    "\n",
    "# Parse storm dates\n",
    "storm_dates = [datetime.strptime(date, '%Y-%m-%dT%H:%M:%S') for date in dates]\n",
    "\n",
    "# Extract unique month-day combinations with landfall years\n",
    "storm_month_day_year = [[date.month, date.day, date.year] for date in storm_dates]\n",
    "storm_month_day = np.unique([[mdy[0], mdy[1]] for mdy in storm_month_day_year], axis=0)\n",
    "\n",
    "# Define special exclusions for specific years based on month and day\n",
    "exclusions = {\n",
    "    (2, 19): [1997],\n",
    "    (12, 15): [1999],\n",
    "    (2, 25): [2002],\n",
    "    (2, 3): [2011],\n",
    "    (2, 1): [2016],\n",
    "    (2, 8): [2016],\n",
    "    (2, 16): [2020],\n",
    "    (2, 28): [1990],\n",
    "}\n",
    "\n",
    "# Helper function to add wrap-around logic for days\n",
    "def get_extended_days(target_month, target_day):\n",
    "    base_date = datetime(2000, target_month, target_day)  # Use 2000 as a dummy year for simplicity\n",
    "    extended_days = [(base_date - timedelta(days=1)).month, (base_date - timedelta(days=1)).day], \\\n",
    "                    [base_date.month, base_date.day], \\\n",
    "                    [(base_date + timedelta(days=1)).month, (base_date + timedelta(days=1)).day]\n",
    "    return extended_days\n",
    "\n",
    "# Process each unique storm day\n",
    "for target_month, target_day in tqdm(storm_month_day):\n",
    "    # Get the extended range of days\n",
    "    extended_days = get_extended_days(target_month, target_day)\n",
    "\n",
    "    # Collect landfall years for all days in the extended range\n",
    "    landfall_years = []\n",
    "    for month, day in extended_days:\n",
    "        landfall_years += [mdy[2] for mdy in storm_month_day_year if mdy[0] == month and mdy[1] == day]\n",
    "\n",
    "    # Exclude specific years\n",
    "    excluded_years = []\n",
    "    for month, day in extended_days:\n",
    "        excluded_years += exclusions.get((month, day), [])\n",
    "    excluded_years += landfall_years\n",
    "    yearin = np.setdiff1d(year, excluded_years)\n",
    "\n",
    "    max_winds_europe = []\n",
    "    for yearz in tqdm(yearin):\n",
    "        for month, day in extended_days:\n",
    "            # Skip non-leap years for Feb 29\n",
    "            if month == 2 and day == 29 and (yearz % 4 != 0 or (yearz % 100 == 0 and yearz % 400 != 0)):\n",
    "                continue\n",
    "\n",
    "            # Load dataset\n",
    "            i10fgpath = f'{ifg}ERA5_{yearz}-{month}_instantaneous_10m_wind_gust.nc'\n",
    "            i10fg = xr.open_dataset(glob.glob(i10fgpath)[0])\n",
    "\n",
    "            # Parse date indices\n",
    "            first_true_index, last_true_index = data_process.parse_date_and_output_list(i10fg, month, day)\n",
    "\n",
    "            # Preprocess dataset\n",
    "            i10fg['longitude'] = ((i10fg['longitude'] + 180) % 360) - 180\n",
    "            i10fg = i10fg.sortby('longitude')\n",
    "            i10fg_europe = i10fg.sel(latitude=slice(71, 30), longitude=slice(-15, 40))\n",
    "            i10fg_europe_date = i10fg_europe.isel(time=slice(first_true_index, last_true_index + 1))\n",
    "\n",
    "            # Calculate maximum wind speed\n",
    "            max_wind_europe = i10fg_europe_date.max(dim='time')\n",
    "            max_winds_europe.append(max_wind_europe)\n",
    "\n",
    "            del i10fg, i10fg_europe\n",
    "            gc.collect()\n",
    "\n",
    "    # Combine and save results\n",
    "    combined_max = xr.concat(max_winds_europe, dim=\"time\").max('time')\n",
    "    dataset_cut = combined_max.where(eu_final_raster['band_data'] == 1).rio.write_crs(\"EPSG:4326\").squeeze().drop_vars('spatial_ref')\n",
    "\n",
    "    #output_path = f\"data/climatology/daily_without_storms/climatology_europe_{target_month}_{target_day}.tif\"\n",
    "    output_path = f\"test/climatology_europe_{target_month}_{target_day}.tif\"\n",
    "    dataset_cut.rio.to_raster(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670fe31",
   "metadata": {},
   "source": [
    "# part for daily max WITHOUT storms included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6cbb345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.57s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.32s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.56s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.31s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.35s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:38<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:41<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.35s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:38<00:00,  1.30s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:41<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.33s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:42<00:00,  1.48s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:39<00:00,  1.31s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.39s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:40<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:40<00:00,  1.40s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.32it/s]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:44<00:00,  1.50s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:45<00:00,  1.51s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:44<00:00,  1.47s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.44s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:39<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.41s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:42<00:00,  1.41s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.45s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:44<00:00,  1.49s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:45<00:00,  1.50s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:43<00:00,  1.46s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:44<00:00,  1.49s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:45<00:00,  1.53s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:48<00:00,  1.62s/it]\n",
      "100%|█████████████████████████████████████████████████| 27/27 [00:43<00:00,  1.62s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:47<00:00,  1.59s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.53s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.37s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:41<00:00,  1.38s/it]\n",
      "100%|█████████████████████████████████████████████████| 30/30 [00:47<00:00,  1.57s/it]\n",
      "100%|█████████████████████████████████████████████████| 28/28 [00:38<00:00,  1.36s/it]\n",
      "100%|█████████████████████████████████████████████████| 28/28 [00:39<00:00,  1.42s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:40<00:00,  1.41s/it]\n",
      "100%|█████████████████████████████████████████████████| 29/29 [00:41<00:00,  1.43s/it]\n",
      "100%|█████████████████████████████████████████████████| 59/59 [41:04<00:00, 41.78s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Load time series dataset\n",
    "dates = pd.read_csv('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/data/time_series_1h_EU/instantaneous_10m_wind_gust/instantaneous_10m_wind_gust_max.csv')['start_date']\n",
    "\n",
    "# Load and preprocess the raster dataset\n",
    "eu_final_raster = xr.open_dataset('pre_processing/maps/eu_final_raster.tif', engine='rasterio').rename({'x': 'longitude', 'y': 'latitude'})\n",
    "\n",
    "# Parse storm dates\n",
    "storm_dates = [datetime.strptime(date, '%Y-%m-%dT%H:%M:%S') for date in dates]\n",
    "\n",
    "# Extract unique month-day combinations with landfall years\n",
    "storm_month_day_year = [[date.month, date.day, date.year] for date in storm_dates]\n",
    "storm_month_day = np.unique([[mdy[0], mdy[1]] for mdy in storm_month_day_year], axis=0)\n",
    "\n",
    "# Define special exclusions for specific years based on month and day\n",
    "exclusions = {\n",
    "    (2, 19): [1997],\n",
    "    (12, 15): [1999],\n",
    "    (2, 25): [2002],\n",
    "    (2, 3): [2011],\n",
    "    (2, 1): [2016],\n",
    "    (2, 8): [2016],\n",
    "    (2, 16): [2020],\n",
    "    (2, 28): [1990],\n",
    "}\n",
    "\n",
    "# Process each unique storm day\n",
    "for target_month, target_day in tqdm(storm_month_day):\n",
    "    # Identify landfall year(s) for the current month-day combination\n",
    "    landfall_years = [mdy[2] for mdy in storm_month_day_year if mdy[0] == target_month and mdy[1] == target_day]\n",
    "    excluded_years = exclusions.get((target_month, target_day), []) + landfall_years\n",
    "    yearin = np.setdiff1d(year, excluded_years)\n",
    "\n",
    "    max_winds_europe = []\n",
    "    for yearz in tqdm(yearin):\n",
    "        # Skip non-leap years for Feb 29\n",
    "        if target_month == 2 and target_day == 29 and (yearz % 4 != 0 or (yearz % 100 == 0 and yearz % 400 != 0)):\n",
    "            continue\n",
    "\n",
    "        # Load dataset\n",
    "        i10fgpath = f'{ifg}ERA5_{yearz}-{target_month}_instantaneous_10m_wind_gust.nc'\n",
    "        i10fg = xr.open_dataset(glob.glob(i10fgpath)[0])\n",
    "\n",
    "        # Parse date indices\n",
    "        first_true_index, last_true_index = data_process.parse_date_and_output_list(i10fg, target_month, target_day)\n",
    "\n",
    "        # Preprocess dataset\n",
    "        i10fg['longitude'] = ((i10fg['longitude'] + 180) % 360) - 180\n",
    "        i10fg = i10fg.sortby('longitude')\n",
    "        i10fg_europe = i10fg.sel(latitude=slice(71, 30), longitude=slice(-15, 40))\n",
    "        i10fg_europe_date = i10fg_europe.isel(time=slice(first_true_index, last_true_index + 1))\n",
    "\n",
    "        # Calculate maximum wind speed\n",
    "        max_wind_europe = i10fg_europe_date.max(dim='time')\n",
    "        max_winds_europe.append(max_wind_europe)\n",
    "\n",
    "        del i10fg, i10fg_europe\n",
    "        gc.collect()\n",
    "\n",
    "    # Combine and save results\n",
    "    combined_max = xr.concat(max_winds_europe, dim=\"time\").max('time')\n",
    "    dataset_cut = combined_max.where(eu_final_raster['band_data'] == 1).rio.write_crs(\"EPSG:4326\").squeeze().drop_vars('spatial_ref')\n",
    "\n",
    "    output_path = f\"data/climatology/daily_without_storms/climatology_europe_{target_month}_{target_day}.tif\"\n",
    "    dataset_cut.rio.to_raster(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcec55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Load time series dataset\n",
    "dates = pd.read_csv('/work/FAC/FGSE/IDYST/tbeucler/default/fabien/repos/cleaner_version/data/time_series_1h_EU/instantaneous_10m_wind_gust/instantaneous_10m_wind_gust_max.csv')['start_date']\n",
    "\n",
    "# Load and preprocess the raster dataset\n",
    "eu_final_raster = xr.open_dataset('pre_processing/maps/eu_final_raster.tif', engine='rasterio').rename({'x': 'longitude', 'y': 'latitude'})\n",
    "\n",
    "# Parse storm dates\n",
    "storm_dates = [datetime.strptime(date, '%Y-%m-%dT%H:%M:%S') for date in dates]\n",
    "\n",
    "# Extract unique month-day combinations with landfall years\n",
    "storm_month_day_year = [[date.month, date.day, date.year] for date in storm_dates]\n",
    "storm_month_day = np.unique([[mdy[0], mdy[1]] for mdy in storm_month_day_year], axis=0)\n",
    "\n",
    "# Define special exclusions for specific years based on month and day\n",
    "exclusions = {\n",
    "    (2, 19): [1997],\n",
    "    (12, 15): [1999],\n",
    "    (2, 25): [2002],\n",
    "    (2, 3): [2011],\n",
    "    (2, 1): [2016],\n",
    "    (2, 8): [2016],\n",
    "    (2, 16): [2020],\n",
    "    (2, 28): [1990],\n",
    "}\n",
    "\n",
    "# Process each unique storm day\n",
    "for target_month, target_day in tqdm(storm_month_day):\n",
    "    # Identify landfall year(s) for the current month-day combination\n",
    "    landfall_years = [mdy[2] for mdy in storm_month_day_year if mdy[0] == target_month and mdy[1] == target_day]\n",
    "    excluded_years = exclusions.get((target_month, target_day), []) + landfall_years\n",
    "    yearin = np.setdiff1d(year, excluded_years)\n",
    "\n",
    "    max_winds_europe = []\n",
    "    for yearz in tqdm(yearin):\n",
    "        # Skip non-leap years for Feb 29\n",
    "        if target_month == 2 and target_day == 29 and (yearz % 4 != 0 or (yearz % 100 == 0 and yearz % 400 != 0)):\n",
    "            continue\n",
    "\n",
    "        # Load dataset\n",
    "        i10fgpath = f'{ifg}ERA5_{yearz}-{target_month}_instantaneous_10m_wind_gust.nc'\n",
    "        i10fg = xr.open_dataset(glob.glob(i10fgpath)[0])\n",
    "\n",
    "        # Parse date indices\n",
    "        first_true_index, last_true_index = data_process.parse_date_and_output_list(i10fg, target_month, target_day)\n",
    "\n",
    "        # Preprocess dataset\n",
    "        i10fg['longitude'] = ((i10fg['longitude'] + 180) % 360) - 180\n",
    "        i10fg = i10fg.sortby('longitude')\n",
    "        i10fg_europe = i10fg.sel(latitude=slice(71, 30), longitude=slice(-15, 40))\n",
    "        i10fg_europe_date = i10fg_europe.isel(time=slice(first_true_index, last_true_index + 1))\n",
    "\n",
    "        # Calculate maximum wind speed\n",
    "        max_wind_europe = i10fg_europe_date.max(dim='time')\n",
    "        max_winds_europe.append(max_wind_europe)\n",
    "\n",
    "        del i10fg, i10fg_europe\n",
    "        gc.collect()\n",
    "\n",
    "    # Combine and save results\n",
    "    combined_max = xr.concat(max_winds_europe, dim=\"time\").max('time')\n",
    "    dataset_cut = combined_max.where(eu_final_raster['band_data'] == 1).rio.write_crs(\"EPSG:4326\").squeeze().drop_vars('spatial_ref')\n",
    "\n",
    "    output_path = f\"data/climatology/daily_without_storms/climatology_europe_{target_month}_{target_day}.tif\"\n",
    "    dataset_cut.rio.to_raster(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
